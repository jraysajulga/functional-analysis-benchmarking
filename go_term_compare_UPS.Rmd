---
title: "Compare GO Terms"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Necessary packages:

```{r message=FALSE}
library(dplyr)
library(stringr)
```

# GO terms, direct from tools

## eggNOG
```{r}
eggnog1 <- read.delim("eggnogmap_results/UPS/UPS1_03_eggNOG_Mapper_on_data_25__diamond.annotations.tabular",
                     stringsAsFactors = FALSE,
                     header = FALSE)
eggnog2 <- read.delim("eggnogmap_results/UPS/UPS2_03_eggNOG_Mapper_on_data_26__diamond.annotations.tabular",
                     stringsAsFactors = FALSE,
                     header = FALSE)

# get all unique go terms from all peptides
eggnog_gos1 <- unlist(str_split(eggnog1$V6, ",")) %>% unique()
eggnog_gos2 <- unlist(str_split(eggnog2$V6, ",")) %>% unique()

eggnog_gos <- c(eggnog_gos1, eggnog_gos2)

# take out empty entry
eggnog_gos_clean <- eggnog_gos[str_sub(eggnog_gos, 1, 2) == "GO"]
```

We are going to write the lists to file, for later use in Python. First, I define a function `clean_write()` which writes a list without all the quotes and stuff:
```{r}
clean_write <- function(object, file){
    write.table(object, file=file, quote = FALSE, row.names = FALSE, col.names = FALSE)
}
```

Write list to file for later use:
```{r}
eggnog_list_file <- "go_lists/UPS/eggnog.tab"
clean_write(eggnog_gos_clean, file=eggnog_list_file)
```

## MetaGOmics
```{r}
metagomics <- read.delim("metaGOmics_results/UPS/MetaGOmics_Compare_UPS2_UPS1.txt",
                             stringsAsFactors = FALSE,
                             comment.char = "#")
metagomics_gos <- metagomics$GO.acc %>%  unique()
# takes out "unknownprc", "unknowncmp", "unknownfun"
metagomics_gos_clean <- metagomics_gos[str_sub(metagomics_gos, 1, 2) == "GO"]
clean_write(metagomics_gos_clean, file="go_lists/UPS/metagomics.tab")
```

## MEGAN6

These go terms come from querying the eggNOG database with the orthologous group ids, contained in `MEGAN_outputs/737NSvsWS_EGGNOGcount.csv`. The Python function to do this is in `MEGAN_outputs/get_gos_from_ogs.py`. 

```{r}
megan <- read.delim("MEGAN_outputs/UPS/go_terms.txt",
                        header = TRUE,
                        stringsAsFactors = FALSE)
megan_go_lists <- megan$go
megan_gos <- unlist(str_split(megan_go_lists, pattern = ",")) %>% unique()
megan_gos_clean <- megan_gos[str_sub(megan_gos, 1, 2) == "GO" & !is.na(megan_gos)]
clean_write(megan_gos_clean, file="go_lists/UPS/megan.tab")
```

## Unipept

For Unipept, the results are divided into BP, MF, and CC files, so I combine the three ontologies for WS and NS. 

```{r}
unipept_results_NS <- paste('unipept_results/',
                               list.files("unipept_results/", pattern = "^737NS.*\\.csv"),
                               sep = "")
unipept_results_WS <- paste('unipept_results/',
                               list.files("unipept_results/", pattern = "^737WS.*\\.csv"),
                               sep = "")
unipeptNS <- lapply(unipept_results_NS, function(i) {
        read.delim(i, sep = ',', as.is = TRUE)}) %>%
    bind_rows() %>%
    select(-X) %>%
    rename(peptides = X.peptides)
unipeptWS <- lapply(unipept_results_WS, function(i) {
    read.delim(i, sep = ',', as.is = TRUE)}) %>%
    bind_rows() %>%
    select(-X) %>%
    rename(peptides = X.peptides)

unipept_all <- inner_join(unipeptNS, unipeptWS, by = c("GO.term", "Name")) %>%
    rename(countNS = peptides.x, countWS = peptides.y) %>%
    mutate(log2ratio = log(countWS/countNS))

unipept_gos <- unipept_all$GO.term %>% unique()
unipept_gos_clean <- unipept_gos[str_sub(unipept_gos, 1, 2) == "GO"]
clean_write(unipept_gos_clean, file="go_lists/unipept.tab")
```

```{r}
unipept_results_NS <- paste('unipept_results/UPS/',
                               list.files("unipept_results/UPS/", pattern = "^737NS.*\\.tabular"),
                               sep = "")
unipept_results_WS <- paste('unipept_results/UPS/',
                               list.files("unipept_results/UPS/", pattern = "^737WS.*\\.tabular"),
                               sep = "")
unipeptNS <- read.delim('unipept_results/UPS/737WS_Galaxy8-[Unipept_pept2go_on_data_2_GO_tsv].tabular', sep = '\t', as.is = TRUE)
unipeptWS <- read.delim('unipept_results/UPS/737NS_Galaxy5-[Unipept_pept2go_on_data_1_GO_tsv].tabular', sep = '\t', as.is = TRUE)

unipept_gos <- c(unique(unipeptNS[,3]),unique(unipeptWS[,3]))

unipept_gos_clean <- unipept_gos[str_sub(unipept_gos, 1, 2) == "GO"]
clean_write(unipept_gos_clean, file="go_lists/UPS/unipept.tab")
#unipeptNS[,3], unipeptWS[,3]
```

## MetaProteomeAnalyzer

Here, we get the Uniprot IDs from all of the files, then upload them to the UniProt "Retrieve/ID Mapping" service (https://www.uniprot.org/uploadlists/).  

```{r}
require(gdata)

# get all uniprot ids
protNS <- read.xls("mpa_results/UPS/UPS1_03_MPA_Analysis.xlsx", sheet = "Proteins", header = TRUE) %>%
    select("prot" = Protein.Accession) %>% unique()

protWS <- read.xls("mpa_results/UPS/UPS1_03_MPA_Analysis.xlsx", sheet = "Proteins", header = TRUE) %>%
    select("prot" = Protein.Accession) %>% unique()

protAll <- rbind(protNS, protWS) %>% unique()

# write for use on uniprot
clean_write(protAll, file="mpa_results/UPS/all_proteins.tab")

```
```{r}
# these are the uniprot results from the above file
mpa_uniprot <- read.delim('mpa_results/UPS/uniprot_protein_results.tab', stringsAsFactors = FALSE)
mpa_gos <- str_trim(unlist(str_split(mpa_uniprot$Gene.ontology.IDs, ";")))
mpa_gos_clean <- mpa_gos[str_sub(mpa_gos, 1, 2) == "GO"] %>% unique()
clean_write(mpa_gos_clean, file="go_lists/UPS/mpa.tab")
```


```{r}
prophane <- read.delim("prophane_results/summary_UPS.txt", sep = "\t",
                             stringsAsFactors = FALSE)
prophane_gos <- c(prophane$task_6..fun_from_TIGRFAMs_15_cut_tc..tigrfam2GO,
    prophane$task_7..fun_from_PFAMs_32..pfam2GO,
  prophane$task_8..fun_from_eggNog_4.5.1..og2GO)
prophane_gos <- prophane_gos[prophane_gos != "-"] %>% unique()
prophane_gos <- trimws(unlist(strsplit(prophane_gos, ","))) %>% unique()
prophane_gos_clean <- prophane_gos[str_sub(prophane_gos, 1, 2) == "GO"]
clean_write(prophane_gos_clean, file="go_lists/UPS/prophane.tab")
```


## Euler Diagram of Results
```{r}
gos <- list('megan' = megan_gos_clean,
            'metagomics' = metagomics_gos_clean,
            'unipept' = unipept_gos_clean,
            'eggnog' = eggnog_gos_clean,
            'mpa' = mpa_gos_clean)
```

# GO terms: all parents

Each of the tools produces a list of GO terms, but we don't necessarily know how the tools assign terms - if a protein or peptide matches a single term, some tools might annotate that protein or peptide with the term and all of its ancestors, while some might annotate the tool with only the term itself. Thus, to reduce this kind of bias, we get all of the ancestors of all of the annotated terms, and produce another Venn diagram.  

Download the current GO ontology:
```{bash results='hide'}
wget http://purl.obolibrary.org/obo/go/go-basic.obo -O GO_files/go-basic.obo
wget http://www.geneontology.org/ontology/subsets/goslim_generic.obo -O GO_files/go-slim.obo
```

Run python to get the list of all ancestors:

```{python engine.path='~/miniconda3/bin/python'}
from goatools import obo_parser
from goatools import mapslim
import sys

go = obo_parser.GODag('GO_files/go-basic.obo')
goslim = obo_parser.GODag('GO_files/go-slim.obo')

def set_of_all_ancestors(terms):
    all_ancestors = set(terms)
    for i in set(terms):
        if i in go.keys():
            all_ancestors.update(go[i].get_all_parents())
    return all_ancestors

def get_all_ancestors(infile, outfile):
    f = open(infile, 'r')
    gos = [x.strip() for x in f.readlines()]
    f.close()
    
    gos_with_ancestors = set_of_all_ancestors(gos)
    
    with open(outfile, 'w') as outf:
        for x in gos_with_ancestors:
            outf.write(x + '\n')

def slim_down(infile, outfile):
    f = open(infile, 'r')
    gos = [x.strip() for x in f.readlines()]
    f.close()
    
    slims = set()
    for i in gos:
        if i in go.keys():
            slims.update(mapslim.mapslim(i, go, goslim)[1])
        else:
            print(i + " not found")
    
    with open(outfile, 'w') as outf:
        for x in slims:
            outf.write(x + '\n')
            
for i in ['eggnog', 'megan', 'metagomics', 'unipept', 'mpa']:
    infile = 'go_lists/UPS/' + i + '.tab'
    outfile = 'go_lists/UPS/' + i + '_parents.tab'
    outslim = 'go_lists/UPS/' + i + '_slim.tab'
    get_all_ancestors(infile, outfile)
    print(i)
    slim_down(infile, outslim)
```

Read ancestors into R. 

```{r}
methods <- c("megan", "metagomics", "unipept", "eggnog", 'mpa')
gos_ancestors <- lapply(methods,
    function(f) {
        "go" = read.delim(paste("go_lists/UPS/", f, '_parents.tab', sep = ""),
                              header = FALSE,
                              stringsAsFactors=FALSE)$V1
    }
)
names(gos_ancestors) <- methods
```

# Results:

## Number of GO terms in each tool

Without ancestors
```{r}
sapply(gos, length)
```

With ancestors
```{r}
sapply(gos_ancestors, length)
```

Unique to each tool
```{r}
ex <- rep(0, 5)
for (i in 1:5){
    all <- 1:5
    other_ind <- all[-i]
    others <- unique(c(unlist(gos[other_ind])))
    ex[i] <- length(setdiff(gos[[i]], others))
}
names(ex) <- names(gos)
```

## GO terms in GOslim

```{r}
methods <- c("megan", "metagomics", "unipept", "eggnog", 'mpa')
gos_slims <- lapply(methods,
    function(f) {
        "go" = read.delim(paste("go_lists/UPS/", f, '_slim.tab', sep = ""),
                              header = FALSE,
                              stringsAsFactors=FALSE)$V1
    }
)
names(gos_slims) <- methods

exslim <- rep(0, 5)
for (i in 1:5){
    all <- 1:5
    other_ind <- all[-i]
    others <- unique(c(unlist(gos_slims[other_ind])))
    exslim[i] <- length(setdiff(gos_slims[[i]], others))
}
names(exslim) <- methods
```

## Jaccard distance 

```{r}
jaccard <- function(vec1, vec2){
    c1 <- length(vec1)
    c2 <- length(vec2)
    int <- length(intersect(vec1, vec2))
    (int) / (c1 + c2 - int)
}

jacmat <- matrix(0, nrow = 5, ncol = 5)
for (i in 1:5){
    for (j in 1:5){
        jacmat[i, j] <- jaccard(gos[[i]], gos[[j]])
    }
}
dimnames(jacmat) <- list(names(gos), names(gos))
jacmat

jacslim <- matrix(0, nrow = 5, ncol = 5)
for (i in 1:5){
    for (j in 1:5){
        jacslim[i, j] <- jaccard(gos_slims[[i]], gos_slims[[j]])
    }
}
dimnames(jacslim) <- list(names(gos), names(gos))
jacslim
```

Levelplots
```{r fig.width = 14}
library(reshape2)
library(ggplot2)
jac_melt <- melt(jacmat)
jac_melt$method <- "Full GO"

jac_melt_slim <- melt(jacslim)
jac_melt_slim$method <- "Slim GO"

jac_melt_all <- rbind(jac_melt, jac_melt_slim)
ggplot(jac_melt_all)+
    geom_tile(aes(x = Var1, y = Var2, fill = value), color = "black") +
    geom_text(aes(x = Var1, y = Var2, label = format(value, digits = 2))) + 
    scale_fill_gradient(name="Jaccard\nIndex", low = "white", high = "dodgerblue", limits = c(0, 1),
                    guide = guide_colorbar(frame.colour = "black", ticks.colour = "black")) +
    facet_grid(.~method) +
    theme_minimal(base_size = 14) +
    theme(aspect.ratio = 1) +
    labs(x = NULL, y = NULL)
ggsave("jaccard_UPS.png", height = 5, width = 12, units = "in", dpi = 700)
```